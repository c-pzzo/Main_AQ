{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1972762e",
   "metadata": {},
   "source": [
    "# About\n",
    "Hyperparameter optimization is required to get the most out of your machine learning models.\n",
    "\n",
    "Hyperparameters are points of choice or configuration that allow a machine learning model to be customized for a specific task or dataset.\n",
    "\n",
    "Parameters are different from hyperparameters. Parameters are learned automatically; hyperparameters are set manually to help guide the learning process.\n",
    "\n",
    "Choosing a hyperparameter grid is probably the most difficult part of hyperparameter tuning: it's nearly impossible ahead of time to say which values of hyperparameters will work well and the optimal settings will depend on the dataset. Moreover, the hyperparameters have complex interactions with each other which means that just tuning one at a time doesn't work because when we start changing other hyperparameters that will affect the one we just tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b78e61",
   "metadata": {},
   "source": [
    "! https://practicaldatascience.co.uk/machine-learning/how-to-use-model-selection-and-hyperparameter-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b72428",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d4cf86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection with MySQL database is ready!\n"
     ]
    }
   ],
   "source": [
    "%run \"../../main_global.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c39796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f55c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pytictoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f177fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "# Save trained models\n",
    "import joblib\n",
    "\n",
    "# Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "# Hypertuning tools\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import SCORERS\n",
    "\n",
    "# Nonlinear models\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "# Ensemble models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Random seed\n",
    "from numpy.random import seed\n",
    "seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2836581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytictoc import TicToc\n",
    "t = TicToc() #create instance of class\n",
    "s = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa64624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import max_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69844e52",
   "metadata": {},
   "source": [
    "# User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9951478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multivariate_samples(object):\n",
    "    \"\"\"\n",
    "    Sequential processing of data to obtain time series.\n",
    "    \n",
    "    Activities:\n",
    "    - initial_df: Read SQL dataset for specific station number.\n",
    "    - samples_creation: Creation of samples array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, table_name, target, cols = '*', where = \"\"):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "        * station_number: Database station number to process\n",
    "        \"\"\"\n",
    "        self.table_name = table_name\n",
    "        self.cols = cols\n",
    "        self.where = where\n",
    "        self.target = target\n",
    "        \n",
    "    def initial_df(self):\n",
    "        # Read raw dataset components from SQL database\n",
    "        sql_df = qdata(\"Select {} from {} {}\".format(self.cols, self.table_name, self.where))\n",
    "        \n",
    "        if self.cols == '*':\n",
    "            col_names = [i[0] for i in qdata(\"show columns from {}\".format(self.table_name))]\n",
    "        else: \n",
    "            col_names = self.cols.split(', ')\n",
    "\n",
    "        # Create dataframe\n",
    "        df = pd.DataFrame(sql_df)\n",
    "        df.columns = col_names\n",
    "\n",
    "        # Set `datetime` column as dataframe index\n",
    "        df = df.set_index('datetime')\n",
    "        df.sort_index(inplace=True)\n",
    "        \n",
    "        # Save temporary array with unmodified target information\n",
    "        target_arr = df[self.target]\n",
    "        \n",
    "        # Data normalization\n",
    "        df=(df-df.min())/(df.max()-df.min())\n",
    "        df = df.fillna(0)\n",
    "        df[self.target] = target_arr\n",
    "\n",
    "        # Overview\n",
    "        return df\n",
    "    \n",
    "    def samples_creation(self, n_steps, target_name):\n",
    "        \"\"\"\n",
    "        Transformation of Dataframe object into numpy.ndarray objects (input, output)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Rearrangin dataset to place target as last column\n",
    "        df = self.initial_df()\n",
    "        \n",
    "        target_col = df[target_name]\n",
    "\n",
    "        df = df.loc[:, df.columns != target_name]\n",
    "        df[target_name] = target_col     \n",
    "        \n",
    "        arr = df.to_numpy()\n",
    "        del target_col\n",
    "        \n",
    "        # Creating samples\n",
    "        tmp = list(reversed(range(len(arr)+1)))\n",
    "        tmp = tmp[:-n_steps][::-1]\n",
    "        tmp = pd.DataFrame(tmp).reset_index(drop = False)\n",
    "        tmp.columns = [\"index\", \"end_ix\"]\n",
    "        \n",
    "        # Create empty lists \n",
    "        X, y = list(), list()\n",
    "\n",
    "        for i, end_ix in zip(tmp[\"index\"], tmp[\"end_ix\"]):\n",
    "            \n",
    "            # Gather input and output parts of the pattern\n",
    "            seq_x, seq_y = arr[i:end_ix, :-1], arr[end_ix-1, -1]\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)        \n",
    "        \n",
    "        return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27563f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_tuning(name, model, space, X, y):\n",
    "    # The searching algorithm includes a “cv” argument that allows:\n",
    "    # a) An integer number of folds to be specified, e.g. 5\n",
    "    #cross_val = 5\n",
    "    # b) A configured cross-validation object.\n",
    "    kfold = KFold(n_splits=3, shuffle=False)\n",
    "\n",
    "    # The scoring metric must be maximizing, meaning better models result in larger scores.\n",
    "    scoring_metric = 'neg_mean_squared_error'\n",
    "\n",
    "    # Search for best hyperparameters\n",
    "    grid = RandomizedSearchCV(estimator=model, \n",
    "                              param_distributions=search_space, \n",
    "                              cv=kfold, \n",
    "                              n_iter=100,\n",
    "                              scoring=scoring_metric)\n",
    "\n",
    "    result = grid.fit(X_test, y_test)\n",
    "    \n",
    "    # Save the trained model\n",
    "    filename = 'ml_trained_models/{}.sav'.format(name)\n",
    "    joblib.dump(result, filename)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d253219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a single model\n",
    "def single_model_evaluation(X_test, y_test, name):\n",
    "    # Load the trained model\n",
    "    filename = 'ml_trained_models/{}.sav'.format(name)\n",
    "    model = joblib.load(filename)\n",
    "\n",
    "    # make predictions\n",
    "    y_prediction = model.predict(X_test)\n",
    "    \n",
    "    metrics = dict()\n",
    "    # evaluate predictions\n",
    "    metrics[\"RMSE\"] = mean_squared_error(y_test, y_prediction, squared=False)\n",
    "    metrics[\"MAE\"] = mean_absolute_error(y_test, y_prediction)\n",
    "    metrics[\"MAPE (%)\"] = mean_absolute_percentage_error(y_test, y_prediction) *100\n",
    "    metrics[\"R^2 (%)\"] = r2_score(y_test, y_prediction) * 100\n",
    "    metrics[\"Max Error\"] = max_error(y_test, y_prediction)    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7660cd23",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c08cdff",
   "metadata": {},
   "source": [
    "## Sample preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d22dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_table = \"sima_station_MVI_MICE_CE\"\n",
    "target = \"pm25\"\n",
    "\n",
    "# Define columns of interest from sql table\n",
    "#     Select all columns:\n",
    "column = \"datetime, co, no, no2, o3, pm10, pm25, prs, rh, so2, sr, tout, wdr, wsr\"\n",
    "# We remove NOx because it has high correlation with NO. Also rainf because it barely has any information\n",
    "\n",
    "#column = \"*\"\n",
    "#     Select specific columns:\n",
    "#column = \"datetime, co, no, no2, nox, o3, pm10, pm25, prs, rainf, rh, so2, sr, tout, wdr, wsr \"\n",
    "\n",
    "# Filter data with WHERE command\n",
    "sql_where = \"where datetime >=\\'2021-04-17 23:00:00\\'\"\n",
    "#\"where datetime > \\'2020-04-20\\'\"\n",
    "\n",
    "# Initialize class to create multivariate samples:\n",
    "multi_ts = multivariate_samples(sql_table, target, column, sql_where)\n",
    "\n",
    "# Datasets can't be trained with sample batches by default. So parameter is 1.\n",
    "X, y = multi_ts.samples_creation(1, target)\n",
    "\n",
    "# Training and test datasets are prepared, avoiding shuffling because it is a time series.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:,0,:], y, test_size = 0.30, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b56c7073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'continuous'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_of_target(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f7bd2f",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b04d179",
   "metadata": {},
   "source": [
    "## Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1adcfceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa61ce7",
   "metadata": {},
   "source": [
    "# Random Search\n",
    "RandomizedSearchCV for random search evaluates models for a given hyperparameter vector using cross-validation, hence the “CV” suffix of each class name.\n",
    "\n",
    "It requires two arguments. \n",
    "1. The first is the model that you are optimizing. This is an instance of the model with values of hyperparameters set that you want to optimize. \n",
    "2. The second is the search space. This is defined as a dictionary where the names are the hyperparameter arguments to the model and the values are discrete values or a distribution of values to sample in the case of a random search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f606afc",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb794f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = KNeighborsRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0750b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    'n_neighbors': list(range(1,10)),\n",
    "    'weights': list(['uniform', 'distance']),\n",
    "    'algorithm': list(['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "    'leaf_size': list(range(15, 45)),\n",
    "    'p': list([1,2]),\n",
    "    'metric': list(['euclidean', 'manhattan','chebyshev', 'minkowski']),\n",
    "    # The search can be made parallel using various if not all of your CPU cores \n",
    "    # We can set it to -1 to automatically use all of the cores in the system.\n",
    "    'n_jobs': list([-1])\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bafdedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 12.963648 seconds.\n",
      "-133.3859987640618\n",
      "\n",
      "KNeighborsRegressor(algorithm='kd_tree', leaf_size=18, n_jobs=-1, n_neighbors=9,\n",
      "                    p=1, weights='distance')\n",
      "\n",
      "{'weights': 'distance', 'p': 1, 'n_neighbors': 9, 'n_jobs': -1, 'metric': 'minkowski', 'leaf_size': 18, 'algorithm': 'kd_tree'}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_KNN = hyper_tuning(\"KNN\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "# Get the results\n",
    "print(result_KNN.best_score_)\n",
    "print(\"\")\n",
    "print(result_KNN.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_KNN.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297245af",
   "metadata": {},
   "source": [
    "## Classification and Regression Tree\n",
    "DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b303d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = DecisionTreeRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94ce5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    'criterion': list(['squared_error', 'friedman_mse', 'absolute_error', 'poisson'])\n",
    "    , 'splitter': list(['best', 'random'])\n",
    "    , 'max_depth': list(range(1,10))\n",
    "    , 'min_samples_split': list(range(2,10))\n",
    "    , 'min_samples_leaf': list(range(1,10))\n",
    "    , 'min_weight_fraction_leaf': list(np.linspace(0.0,0.5))\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32313cfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 2.908043 seconds.\n",
      "-170.69338613567842\n",
      "\n",
      "DecisionTreeRegressor(criterion='friedman_mse', max_depth=9, min_samples_leaf=9,\n",
      "                      min_samples_split=7,\n",
      "                      min_weight_fraction_leaf=0.02040816326530612)\n",
      "\n",
      "{'splitter': 'best', 'min_weight_fraction_leaf': 0.02040816326530612, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_depth': 9, 'criterion': 'friedman_mse'}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_DTR = hyper_tuning(\"DecisionTrees\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_DTR.best_score_)\n",
    "print(\"\")\n",
    "print(result_DTR.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_DTR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b3674",
   "metadata": {},
   "source": [
    "## Support Vector Regression - Polynomial\n",
    "svm.SVR(kernel='poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cc46eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'cache_size': 200,\n",
       " 'coef0': 0.0,\n",
       " 'degree': 3,\n",
       " 'epsilon': 0.1,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = svm.SVR()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abcdc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    'kernel': list(['poly'])\n",
    "    # `degree` is a parameter used when kernel is set to ‘poly’.\n",
    "    , 'degree': list([0, 2, 3, 4, 5, 6])\n",
    "    # Gamma is a parameter for non linear hyperplanes. \n",
    "    # The higher the gamma value it tries to exactly fit the training data set\n",
    "    , 'gamma' : list([0.1, 1, 10, 100])\n",
    "    # C is the penalty parameter of the error term. \n",
    "    # It controls the trade off between smooth decision boundary and classifying the training points correctly.\n",
    "    , 'C': list([0.1, 1, 10, 100, 1000])\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4df7656f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if(False):\n",
    "    t.tic()\n",
    "    result_SVM_poly = hyper_tuning(\"SVR_Poly\", model, search_space, X_train, y_train)\n",
    "    t.toc(restart=True)\n",
    "\n",
    "    # Get the results\n",
    "    print(result_SVM_poly.best_score_)\n",
    "    print(\"\")\n",
    "    print(result_SVM_poly.best_estimator_)\n",
    "    print(\"\")\n",
    "    print(result_SVM_poly.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31d89a",
   "metadata": {},
   "source": [
    "## Support Vector Regression - RBF\n",
    "svm.SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94870cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'cache_size': 200,\n",
       " 'coef0': 0.0,\n",
       " 'degree': 3,\n",
       " 'epsilon': 0.1,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = svm.SVR()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf4a6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    'kernel': list(['rbf'])\n",
    "    # Gamma is a parameter for non linear hyperplanes. \n",
    "    # The higher the gamma value it tries to exactly fit the training data set\n",
    "    , 'gamma' : list([0.1, 1, 10, 100])\n",
    "    # C is the penalty parameter of the error term. \n",
    "    # It controls the trade off between smooth decision boundary and classifying the training points correctly.\n",
    "    , 'C': list([0.1, 1, 10, 100, 1000])\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88de60fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/anaconda3/envs/hdl_project/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 20 is smaller than n_iter=100. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 29.747079 seconds.\n",
      "-96.31969565267705\n",
      "\n",
      "SVR(C=1000, gamma=0.1)\n",
      "\n",
      "{'kernel': 'rbf', 'gamma': 0.1, 'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_SVM_RBF = hyper_tuning(\"SVR_RBF\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_SVM_RBF.best_score_)\n",
    "print(\"\")\n",
    "print(result_SVM_RBF.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_SVM_RBF.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c99691c",
   "metadata": {},
   "source": [
    "## Support Vector Regression - Linear\n",
    "svm.SVR(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d3c8aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'cache_size': 200,\n",
       " 'coef0': 0.0,\n",
       " 'degree': 3,\n",
       " 'epsilon': 0.1,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = svm.SVR()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5c68ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    'kernel': list(['linear'])\n",
    "    # Gamma is a parameter for non linear hyperplanes. \n",
    "    # The higher the gamma value it tries to exactly fit the training data set\n",
    "    , 'gamma' : list([0.1, 1, 10, 100])\n",
    "    # C is the penalty parameter of the error term. \n",
    "    # It controls the trade off between smooth decision boundary and classifying the training points correctly.\n",
    "    , 'C': list([0.1, 1, 10, 100, 1000])\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b9d57d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/anaconda3/envs/hdl_project/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 20 is smaller than n_iter=100. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 13.959796 seconds.\n",
      "-100.8383024821169\n",
      "\n",
      "SVR(C=100, gamma=0.1, kernel='linear')\n",
      "\n",
      "{'kernel': 'linear', 'gamma': 0.1, 'C': 100}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_SVM_Linear = hyper_tuning(\"SVR_Linear\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_SVM_Linear.best_score_)\n",
    "print(\"\")\n",
    "print(result_SVM_Linear.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_SVM_Linear.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639436d6",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1add929b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = RandomForestRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7abf1537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    # `n_estimators` represents the number of trees in the forest. \n",
    "    # Usually the higher the number of trees the better to learn the data. It is also computationally expensive.\n",
    "    'n_estimators': list([100, 200, 300, 400, 500])\n",
    "    # `max_depth` represents the depth of each tree in the forest. \n",
    "    # The deeper the tree, the more splits it has and it captures more information about the data.\n",
    "    , 'max_depth': list(np.linspace(1, 32, 32, endpoint=True))\n",
    "    # `min_samples_split` represents the minimum number of samples required to split an internal node. \n",
    "    , 'min_samples_split': list([2, 3, 4, 5, 6, 7, 8, 9, 10]) # list(np.linspace(1, 1, 10, endpoint=True))\n",
    "    # `min_samples_leaf` The minimum number of samples required to be at a leaf node.\n",
    "    #, 'min_samples_leafs': list([1, 2, 4])\n",
    "    # `max_features`: Represents the number of features to consider when looking for the best split.\n",
    "    , 'max_features': list(range(1,X_train.shape[1]))\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0d9a3f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 329.859395 seconds.\n",
      "-109.9435418724932\n",
      "\n",
      "RandomForestRegressor(max_depth=22.0, max_features=4, n_estimators=400)\n",
      "\n",
      "{'n_estimators': 400, 'min_samples_split': 2, 'max_features': 4, 'max_depth': 22.0}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_RF = hyper_tuning(\"RandomForest\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results \n",
    "print(result_RF.best_score_)\n",
    "print(\"\")\n",
    "print(result_RF.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_RF.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447f052",
   "metadata": {},
   "source": [
    "## Extra-trees regressor\n",
    "ExtraTreesRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b5ae84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = ExtraTreesRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40ebe9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    # `n_estimators` represents the number of trees in the forest. \n",
    "    # Usually the higher the number of trees the better to learn the data. It is also computationally expensive.\n",
    "    'n_estimators': list([1, 2, 4, 8, 16, 32, 64, 100, 200])\n",
    "    , 'criterion': ['squared_error']\n",
    "    # `max_depth` represents the depth of each tree in the forest. \n",
    "    # The deeper the tree, the more splits it has and it captures more information about the data.\n",
    "    , 'max_depth': list(np.linspace(1, 32, 32, endpoint=True))\n",
    "    # `min_samples_split` represents the minimum number of samples required to split an internal node. \n",
    "    , 'min_samples_split': list([2, 3, 4, 5, 6, 7, 8, 9, 10]) # list(np.linspace(1, 1, 10, endpoint=True))\n",
    "    # `min_samples_leaf` The minimum number of samples required to be at a leaf node.\n",
    "    #, 'min_samples_leafs': list(np.linspace(0.1, 0.5, 5, endpoint=True))\n",
    "    # `max_features`: Represents the number of features to consider when looking for the best split.\n",
    "    , 'max_features': list(range(1,X_train.shape[1]))\n",
    "\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68a98b35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 24.816417 seconds.\n",
      "-103.267230170774\n",
      "\n",
      "ExtraTreesRegressor(max_depth=18.0, max_features=11, min_samples_split=5,\n",
      "                    n_estimators=64)\n",
      "\n",
      "{'n_estimators': 64, 'min_samples_split': 5, 'max_features': 11, 'max_depth': 18.0, 'criterion': 'squared_error'}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_ETR = hyper_tuning(\"ExtraTrees\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_ETR.best_score_)\n",
    "print(\"\")\n",
    "print(result_ETR.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_ETR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2096e",
   "metadata": {},
   "source": [
    "## XG Boost \n",
    "XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "410f4f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = XGBRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a21d4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    'max_depth': [3, 5, 6, 10, 15, 20]\n",
    "    , 'learning_rate': [0.01, 0.1, 0.2, 0.3]\n",
    "    , 'subsample': np.arange(0.5, 1.0, 0.1)\n",
    "    , 'colsample_bytree': np.arange(0.4, 1.0, 0.1)\n",
    "    , 'colsample_bylevel': np.arange(0.4, 1.0, 0.1)\n",
    "    , 'n_estimators': [100, 500, 1000, 1500, 2000]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86644010",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 542.755983 seconds.\n",
      "-97.98322713932491\n",
      "\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=0.6, colsample_bynode=1, colsample_bytree=0.6,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=1000,\n",
      "             n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "\n",
      "{'subsample': 0.5, 'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.6, 'colsample_bylevel': 0.6}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_XGB = hyper_tuning(\"XGBoost\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_XGB.best_score_)\n",
    "print(\"\")\n",
    "print(result_XGB.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_XGB.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00ad9bd",
   "metadata": {},
   "source": [
    "# Loading and evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9f76c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.   12.   10.   ... 22.25 25.19 27.87]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.0, 'MAE': 0.0, 'MAPE (%)': 0.0, 'R^2 (%)': 100.0, 'Max Error': 0.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model\n",
    "filename = 'ml_trained_models/{}.sav'.format(\"KNN\")\n",
    "model = joblib.load(filename)\n",
    "\n",
    "# make predictions\n",
    "y_prediction = model.predict(X_test)\n",
    "\n",
    "metrics = dict()\n",
    "# evaluate predictions\n",
    "metrics[\"RMSE\"] = mean_squared_error(y_test, y_prediction, squared=False)\n",
    "metrics[\"MAE\"] = mean_absolute_error(y_test, y_prediction)\n",
    "metrics[\"MAPE (%)\"] = mean_absolute_percentage_error(y_test, y_prediction) *100\n",
    "metrics[\"R^2 (%)\"] = r2_score(y_test, y_prediction) * 100\n",
    "metrics[\"Max Error\"] = max_error(y_test, y_prediction)    \n",
    "\n",
    "print(y_prediction)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fe6c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a dict of models {name:object}, returns {name:score}\n",
    "def multiple_model_evaluation(X_test, y_test, models_list):\n",
    "    metrics_df = pd.DataFrame()\n",
    "    \n",
    "    for name in models_list:\n",
    "        # evaluate the model\n",
    "        s.tic()\n",
    "        tmp_df = pd.DataFrame(single_model_evaluation(X_test, y_test, name), index=[0])\n",
    "        tmp_df.insert(0, \"Model Name\", name, True)\n",
    "        tmp_df.insert(0, \"Type\", \"ML\", True)\n",
    "        metrics_df = metrics_df.append(tmp_df)\n",
    "        print(\"> {}.\".format(name))\n",
    "        s.toc(restart=True)\n",
    "        \n",
    "    return metrics_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33c72ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> KNN.\n",
      "Elapsed time is 0.220636 seconds.\n",
      "> DecisionTrees.\n",
      "Elapsed time is 0.012958 seconds.\n",
      "> SVR_RBF.\n",
      "Elapsed time is 0.369502 seconds.\n",
      "> SVR_Linear.\n",
      "Elapsed time is 0.165148 seconds.\n",
      "> RandomForest.\n",
      "Elapsed time is 0.317994 seconds.\n",
      "> ExtraTrees.\n",
      "Elapsed time is 0.044833 seconds.\n",
      "> XGBoost.\n",
      "Elapsed time is 0.035049 seconds.\n",
      "Elapsed time is 0.000370 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE (%)</th>\n",
       "      <th>R^2 (%)</th>\n",
       "      <th>Max Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML</td>\n",
       "      <td>DecisionTrees</td>\n",
       "      <td>9.960840</td>\n",
       "      <td>7.083602</td>\n",
       "      <td>56.385265</td>\n",
       "      <td>63.942364</td>\n",
       "      <td>68.625079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML</td>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>8.489852</td>\n",
       "      <td>5.640337</td>\n",
       "      <td>29.947322</td>\n",
       "      <td>73.805777</td>\n",
       "      <td>80.739253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML</td>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>9.628586</td>\n",
       "      <td>6.628575</td>\n",
       "      <td>26.804631</td>\n",
       "      <td>66.307727</td>\n",
       "      <td>80.389328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>2.806154</td>\n",
       "      <td>1.919072</td>\n",
       "      <td>17.787861</td>\n",
       "      <td>97.138272</td>\n",
       "      <td>27.241561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ML</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>1.871815</td>\n",
       "      <td>1.211410</td>\n",
       "      <td>7.609728</td>\n",
       "      <td>98.726699</td>\n",
       "      <td>28.946576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ML</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>3.656935</td>\n",
       "      <td>2.701640</td>\n",
       "      <td>29.296188</td>\n",
       "      <td>95.139960</td>\n",
       "      <td>26.219849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type     Model Name      RMSE       MAE   MAPE (%)     R^2 (%)  Max Error\n",
       "0   ML            KNN  0.000000  0.000000   0.000000  100.000000   0.000000\n",
       "1   ML  DecisionTrees  9.960840  7.083602  56.385265   63.942364  68.625079\n",
       "2   ML        SVR_RBF  8.489852  5.640337  29.947322   73.805777  80.739253\n",
       "3   ML     SVR_Linear  9.628586  6.628575  26.804631   66.307727  80.389328\n",
       "4   ML   RandomForest  2.806154  1.919072  17.787861   97.138272  27.241561\n",
       "5   ML     ExtraTrees  1.871815  1.211410   7.609728   98.726699  28.946576\n",
       "6   ML        XGBoost  3.656935  2.701640  29.296188   95.139960  26.219849"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get model list\n",
    "models_list = [\"KNN\", \"DecisionTrees\", \"SVR_RBF\", \"SVR_Linear\", \"RandomForest\", \"ExtraTrees\", \"XGBoost\"]\n",
    "\n",
    "# evaluate models\n",
    "t.tic() #Start timer\n",
    "results = multiple_model_evaluation(X_test, y_test, models_list)\n",
    "t.toc() #Time elapsed since t.tic()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842f166",
   "metadata": {},
   "source": [
    "# Sources:\n",
    "## Main \n",
    "https://practicaldatascience.co.uk/machine-learning/how-to-use-model-selection-and-hyperparameter-tuning\n",
    "\n",
    "\n",
    "* sklearn.model_selection.RandomizedSearchCV\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html \n",
    "    - https://scikit-learn.org/stable/modules/grid_search.html?highlight=randomsearchcv\n",
    "* sklearn.model_selection.KFold\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "    - https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "\n",
    "\n",
    "## Models\n",
    "* KNN\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html#sklearn.metrics.DistanceMetric\n",
    "* DecisionTreeRegressor()\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "* pmdarima\n",
    "    - https://towardsdatascience.com/efficient-time-series-using-pythons-pmdarima-library-f6825407b7f0\n",
    "* SVM\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html?highlight=svm%20svr%20kernel%20poly\n",
    "    - https://medium.com/all-things-ai/in-depth-parameter-tuning-for-svc-758215394769\n",
    "* Random Forest\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "    - https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d\n",
    "* XGBoost\n",
    "    - https://towardsdatascience.com/xgboost-fine-tune-and-optimize-your-model-23d996fab663\n",
    "    \n",
    "* Gaussian NB\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "    - https://medium.com/analytics-vidhya/how-to-improve-naive-bayes-9fa698e14cba\n",
    "    - https://www.analyticsvidhya.com/blog/2021/01/gaussian-naive-bayes-with-hyperpameter-tuning/\n",
    "    \n",
    "## Metrics\n",
    "* Metrics and scoring: quantifying the quality of predictions\n",
    "    - https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    - https://openclassrooms.com/en/courses/6401081-improve-the-performance-of-a-machine-learning-model/6539936-improve-your-feature-selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
